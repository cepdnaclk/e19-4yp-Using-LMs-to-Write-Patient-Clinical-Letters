{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af293ad5-b8c8-4365-85d5-91e81fd5fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: datasets in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d912bcfc-eda2-4353-9a51-069b92bbfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4d2c88-cf8b-498d-a028-ffce50b82118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd233b9d-9035-4e24-a4d6-fc217dc70e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Visible:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c52233b-f74f-4275-a64d-47bd7c497cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n",
      "Device name: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645c699d-01fd-4ed8-87e3-f2ec877925c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/e19431/miniconda3/envs/venv/lib/python3.11/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e70f1d9-023c-45d8-b696-3a3fe1361faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import sentencepiece\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\")\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Preprocess the dialogues and SOAP notes for tokenization\n",
    "def preprocess_and_tokenize(example):\n",
    "    # Tokenize the dialogue (input text)\n",
    "    input_ids = tokenizer(example[\"dialogue\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Tokenize the SOAP note (target text)\n",
    "    labels = tokenizer(example[\"soap\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # Add labels to the input dictionary\n",
    "    input_ids[\"labels\"] = labels\n",
    "    return input_ids\n",
    "\n",
    "# Apply preprocessing and tokenization to the entire dataset\n",
    "train_dataset = dataset['train'].map(preprocess_and_tokenize, batched=True)\n",
    "val_dataset = dataset['validation'].map(preprocess_and_tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b0fd03-cdcb-4820-862d-30c497795ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/full_parameter\",            # Directory for saving the model\n",
    "    num_train_epochs=3,                               # Number of training epochs\n",
    "    per_device_train_batch_size=16,                   # Batch size for training\n",
    "    per_device_eval_batch_size=16,                    # Batch size for evaluation\n",
    "    warmup_steps=500,                                 # Warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                                # Weight decay to avoid overfitting\n",
    "    logging_dir=\"./logs\",                             # Directory for logging\n",
    "    logging_steps=10,                                 # Log every 10 steps\n",
    "    save_steps=500,                                   # Save the model every 500 steps\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,                               # Keep only the last 2 saved models\n",
    "    load_best_model_at_end=True,                      # Load the best model when finished\n",
    "    report_to=\"none\",\n",
    "    fp16=True,                                        # Enable mixed precision training for faster training\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6473a93b-a29b-424c-832b-2ce5e2d9137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076e591d-3a85-492e-926e-c724a98e22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84523/3547945296.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1737' max='1737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1737/1737 08:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.887300</td>\n",
       "      <td>1.610374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.686200</td>\n",
       "      <td>1.462896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.644000</td>\n",
       "      <td>1.431133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1737, training_loss=2.241065425576324, metrics={'train_runtime': 493.5631, 'train_samples_per_second': 56.224, 'train_steps_per_second': 3.519, 'total_flos': 3755734990848000.0, 'train_loss': 2.241065425576324, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72354c2-2408-4ef9-ae0d-c6c48d86d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./finetuned_t5_small/tokenizer_config.json',\n",
       " './finetuned_t5_small/special_tokens_map.json',\n",
       " './finetuned_t5_small/spiece.model',\n",
       " './finetuned_t5_small/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./finetuned_t5_small')\n",
    "tokenizer.save_pretrained('./finetuned_t5_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532097ae-51ca-412f-a27a-12d6799d0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 100 dialogues from the test set\n",
    "test_dialogues = dataset['test']['dialogue'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d648f0-acd3-4de6-955c-017206152c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"S: The patient reports experiencing painless blurry vision in the right eye for a week, intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on the lower legs for the past 6 months. The patient denies any past medical history including neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity. O: Vital signs were normal. Physical examination revealed bilateral papilledema and optic nerve erythema in the right eye, right inferior nasal quadrant visual field defect, right afferent pupillary defect, and sensation to light touch, pinprick, vibration, and proprioception intact. A: The primary diagnosis is microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit 35.3%, mean corpuscular volume of 76.9 fL, hyponatremia with a sodium level of 133 mmol/L, C-reactive protein (CRP) elevated at 33 mm/hr, and\"]\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and use it\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize and move inputs to the same device as the model\n",
    "inputs = tokenizer(test_dialogues, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}  # Move input tensors to the same device as the model\n",
    "\n",
    "# Generate SOAP notes for these dialogues\n",
    "outputs = model.generate(inputs['input_ids'], max_length=256, num_beams=5, early_stopping=True)\n",
    "\n",
    "# Decode the generated token IDs into readable SOAP notes\n",
    "generated_soap_notes = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "# Print the first few results to check\n",
    "print(generated_soap_notes[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0a38c7-5da0-4b4a-8abe-bd7ddd684a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Save the generated SOAP notes and dialogues to a CSV file\n",
    "with open(\"full-paramater-generated-results.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Dialogue\", \"Generated SOAP Note\"])  # Column headers\n",
    "    for dialogue, soap_note in zip(test_dialogues, generated_soap_notes):\n",
    "        writer.writerow([dialogue, soap_note])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb785a33-c5bd-4804-a645-f6294f1417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('./finetuned_t5_small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('./finetuned_t5_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1e27fe-50b7-43e0-b740-5bdcf87295a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"S: The patient reports experiencing painless blurry vision in the right eye for a week, intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on the lower legs for the past 6 months. The patient denies any past medical history including neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity. O: Vital signs were normal. Physical examination revealed bilateral papilledema and optic nerve erythema in the right eye, right inferior nasal quadrant visual field defect, right afferent pupillary defect, and sensation to light touch, pinprick, vibration, and proprioception intact. A: The primary diagnosis is microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit 35.3%, mean corpuscular volume of 76.9 fL, hyponatremia with a sodium level of 133 mmol/L, C-reactive protein (CRP) elevated at 33 mm/hr, and\", \"S: The patient is a 7-year-old boy with congenital bilateral sensorineural deafness, with a failed right cochlear implant. The patient has a history of congenital bilateral sensorineural deafness and a failed right cochlear implant. O: Recent MRI revealed a size 5.5 mm internal-diameter uncuffed ETT during the MRI. The patient's airway was secured with a size 5.5 mm internal-diameter uncuffed ETT, brainstem mapping of CN IX, X, XI, XII and their motor nuclei, and corticobulbar tract motor-evoked potential (MEP). A 32 mm by 29 mm laryngeal electrode was placed on the ipsilateral soft palate using a C-MAC Laryngoscope. A: The primary diagnosis is CN IX, X, XI, XII, XII, and their motor nuclei, and corticobulbar tract motor-evoked potential. Differential diagnose\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file containing the generated SOAP notes\n",
    "df = pd.read_csv('full-paramater-generated-results.csv')\n",
    "\n",
    "# Extract the generated SOAP notes\n",
    "generated_soap_notes = df['Generated SOAP Note'].tolist()\n",
    "\n",
    "# Print the first few SOAP notes to check\n",
    "print(generated_soap_notes[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6100f823-c0f1-4e2d-8609-9eaa1f22639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': np.float64(0.47853501109237784), 'rouge2': np.float64(0.28087619526826557), 'rougeL': np.float64(0.35051591508349156), 'rougeLsum': np.float64(0.40778387667135596)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\")\n",
    "\n",
    "# Extract the ground truth SOAP notes from the test set\n",
    "ground_truth_soap_notes = dataset['test']['soap'][:100]\n",
    "\n",
    "# Evaluate the ROUGE score by comparing generated SOAP notes with ground truth\n",
    "results = rouge_metric.compute(predictions=generated_soap_notes, references=ground_truth_soap_notes)\n",
    "\n",
    "# Print the ROUGE results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf92d83f-9e02-4988-8774-b7947de29b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.47853501109237784\n",
      "ROUGE-2: 0.28087619526826557\n",
      "ROUGE-L: 0.35051591508349156\n"
     ]
    }
   ],
   "source": [
    "# Accessing specific ROUGE scores\n",
    "rouge_1 = results[\"rouge1\"]\n",
    "rouge_2 = results[\"rouge2\"]\n",
    "rouge_l = results[\"rougeL\"]\n",
    "\n",
    "# Print each of the scores\n",
    "print(f\"ROUGE-1: {rouge_1}\")\n",
    "print(f\"ROUGE-2: {rouge_2}\")\n",
    "print(f\"ROUGE-L: {rouge_l}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
